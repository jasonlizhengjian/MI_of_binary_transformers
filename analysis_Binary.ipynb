{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSdIfvbr2mEH"
      },
      "source": [
        "# Mech Interp of Binarized Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Question being explored: Recent papers have shown that binary and ternary transformer based networks with weights of {-1,1} or {-1,0,1} can achieve similar results to full precision networks. Are these networks simply simulating a full precision network or are they learning different and possibly more interpretable algorithms due to their discretized nature. \n",
        "\n",
        "Setup: A 1 layer transformer with all weights binarized except for the embed and unembed. The specific implementation is based off of the BitNet paper and code is in the BitNet folder. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLgcJNgR2mEI"
      },
      "source": [
        "# Setup\n",
        "(No need to read)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPIr5fE42mEI"
      },
      "outputs": [],
      "source": [
        "TRAIN_MODEL = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEc0j-jF2mEI",
        "outputId": "47b7cca7-3dbb-4a56-9154-a038c428e8c2"
      },
      "outputs": [],
      "source": [
        "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
        "DEVELOPMENT_MODE = True\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "    %pip install transformer-lens\n",
        "    %pip install circuitsvis\n",
        "\n",
        "    # PySvelte is an unmaintained visualization library, use it as a backup if circuitsvis isn't working\n",
        "    # # Install another version of node that makes PySvelte work way faster\n",
        "    # !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
        "    # %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    from IPython import get_ipython\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "    ipython.magic(\"load_ext autoreload\")\n",
        "    ipython.magic(\"autoreload 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cFnRU5u2mEJ",
        "outputId": "3c006ff6-30df-4983-a79b-3ded2df29e59"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import plotly.io as pio\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz4BZXid2mEJ"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQTnA2wD2mEJ"
      },
      "outputs": [],
      "source": [
        "# Import stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "import os\n",
        "import tqdm.auto as tqdm\n",
        "import random\n",
        "from pathlib import Path\n",
        "import plotly.express as px\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from typing import List, Union, Optional\n",
        "from functools import partial\n",
        "import copy\n",
        "\n",
        "import itertools\n",
        "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
        "import dataclasses\n",
        "import datasets\n",
        "from IPython.display import HTML\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zc1xEQ2H2mEJ"
      },
      "outputs": [],
      "source": [
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riybQD-I2mEJ"
      },
      "source": [
        "Plotting helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EpDvaOv2mEK"
      },
      "outputs": [],
      "source": [
        "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
        "    x = utils.to_numpy(x)\n",
        "    y = utils.to_numpy(y)\n",
        "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWVceVHI2mEK"
      },
      "outputs": [],
      "source": [
        "# Define the location to save the model, using a relative path\n",
        "PTH_LOCATION = \"workspace/_scratch/grokking_demo.pth\"\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "os.makedirs(Path(PTH_LOCATION).parent, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZawWw_u2mEK"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK90rYXf2mEK"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0yqsnrN2mEK"
      },
      "outputs": [],
      "source": [
        "p = 113\n",
        "frac_train = 0.3\n",
        "\n",
        "# Optimizer config\n",
        "lr = 1e-3\n",
        "wd = 1.\n",
        "betas = (0.9, 0.98)\n",
        "\n",
        "num_epochs = 10000\n",
        "checkpoint_every = 100\n",
        "\n",
        "DATA_SEED = 598"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgeUbLiv2mEK"
      },
      "source": [
        "## Define Task\n",
        "* Define modular addition\n",
        "* Define the dataset & labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuQn0bHO2mEK"
      },
      "source": [
        "Input format:\n",
        "|a|b|=|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzZ_S5eX2mEK"
      },
      "outputs": [],
      "source": [
        "a_vector = einops.repeat(torch.arange(p), \"i -> (i j)\", j=p)\n",
        "b_vector = einops.repeat(torch.arange(p), \"j -> (i j)\", i=p)\n",
        "equals_vector = einops.repeat(torch.tensor(113), \" -> (i j)\", i=p, j=p)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSMKj8CC2mEK",
        "outputId": "b9b6f98f-5c02-42e6-9d9d-04a3410785f0"
      },
      "outputs": [],
      "source": [
        "dataset = torch.stack([a_vector, b_vector, equals_vector], dim=1).cuda()\n",
        "print(dataset[:5])\n",
        "print(dataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7M57a282mEK",
        "outputId": "925c2e34-2b9e-45c1-95b0-22e9eb53c422"
      },
      "outputs": [],
      "source": [
        "labels = (dataset[:, 0] + dataset[:, 1]) % p\n",
        "print(labels.shape)\n",
        "print(labels[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rABUaFX2mEK"
      },
      "source": [
        "Convert this to a train + test set - 30% in the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKOlf29c2mEK",
        "outputId": "b3cebea4-e3b3-4ffa-e68a-0d6ddf0dca5e"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(DATA_SEED)\n",
        "indices = torch.randperm(p*p)\n",
        "cutoff = int(p*p*frac_train)\n",
        "train_indices = indices[:cutoff]\n",
        "test_indices = indices[cutoff:]\n",
        "\n",
        "train_data = dataset[train_indices]\n",
        "train_labels = labels[train_indices]\n",
        "test_data = dataset[test_indices]\n",
        "test_labels = labels[test_indices]\n",
        "print(train_data[:5])\n",
        "print(train_labels[:5])\n",
        "print(train_data.shape)\n",
        "print(test_data[:5])\n",
        "print(test_labels[:5])\n",
        "print(test_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moB_cs6p2mEK"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1w97OT02mEL"
      },
      "outputs": [],
      "source": [
        "\n",
        "cfg = HookedTransformerConfig(\n",
        "    n_layers = 1,\n",
        "    n_heads = 4,\n",
        "    d_model = 128,\n",
        "    d_head = 32,\n",
        "    d_mlp = 512,\n",
        "    act_fn = \"relu\",\n",
        "    normalization_type=None,\n",
        "    d_vocab=p+1,\n",
        "    d_vocab_out=p,\n",
        "    n_ctx=3,\n",
        "    init_weights=True,\n",
        "    device=\"cuda\",\n",
        "    seed = 999,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bitnet import BitNetTransformer\n",
        "\n",
        "model2 = BitNetTransformer(dim=128, depth=1, heads=4, in_features=p+1, out_features=p, random_seed=999,mode='binary').to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnLKZ1st2mEL"
      },
      "source": [
        "Disable the biases, as we don't need them for this task and it makes things easier to interpret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Pud0zFG2mEL"
      },
      "outputs": [],
      "source": [
        "for name, param in model2.named_parameters():\n",
        "    if \"b_\" in name:\n",
        "        param.requires_grad = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52MaWWa92mEL"
      },
      "source": [
        "## Define Optimizer + Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer2  = torch.optim.AdamW(model2.parameters(), lr=lr, weight_decay=wd, betas=betas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTDFhMrA2mEL",
        "outputId": "8b767b93-8723-4777-bbc3-9d9eeca95b6a"
      },
      "outputs": [],
      "source": [
        "def loss_fn(logits, labels):\n",
        "    if len(logits.shape)==3:\n",
        "        logits = logits[:, -1]\n",
        "    logits = logits.to(torch.float64)\n",
        "    log_probs = logits.log_softmax(dim=-1)\n",
        "    correct_log_probs = log_probs.gather(dim=-1, index=labels[:, None])[:, 0]\n",
        "    return -correct_log_probs.mean()\n",
        "train_logits = model2(train_data)\n",
        "print(train_logits.shape)\n",
        "train_loss = loss_fn(train_logits, train_labels)\n",
        "print(train_loss)\n",
        "test_logits = model2(test_data)\n",
        "test_loss = loss_fn(test_logits, test_labels)\n",
        "print(test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aufW9n-2mEL",
        "outputId": "0193b2a9-b319-4422-efe3-3bb1b0de8bf8"
      },
      "outputs": [],
      "source": [
        "print(\"Uniform loss:\")\n",
        "print(np.log(p))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMWao8K42mEL"
      },
      "source": [
        "## Actually Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "model_checkpoints = []\n",
        "checkpoint_epochs = []\n",
        "if True:\n",
        "    for epoch in tqdm.tqdm(range(num_epochs)):\n",
        "        train_logits = model2(train_data)\n",
        "        train_loss = loss_fn(train_logits, train_labels)\n",
        "        train_loss.backward()\n",
        "        train_losses.append(train_loss.item())\n",
        "\n",
        "        optimizer2.step()\n",
        "        optimizer2.zero_grad()\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            test_logits = model2(test_data)\n",
        "            test_loss = loss_fn(test_logits, test_labels)\n",
        "            test_losses.append(test_loss.item())\n",
        "\n",
        "        if ((epoch+1)%checkpoint_every)==0:\n",
        "            # checkpoint_epochs.append(epoch)\n",
        "            # model_checkpoints.append(copy.deepcopy(model.state_dict()))\n",
        "            print(f\"Epoch {epoch} Train Loss {train_loss.item()} Test Loss {test_loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2.state_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Above is the architecture of the model used. We see that all the linear layers in between the embed and unembed are BitLinear. Also note that the RMS norm is added before the unembeding, this was also found to be necessary for the model to actually train. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2.emb\n",
        "W_E = model2.emb.weight\n",
        "W_E = W_E[:-1]\n",
        "print(W_E.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cache = model2.cache\n",
        "print(cache.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "097Jxryq2mEL"
      },
      "source": [
        "## Show Model Training Statistics, Check that it groks!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install git+https://github.com/neelnanda-io/neel-plotly.git\n",
        "from neel_plotly.plot import line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qy7wLT_v2mEL",
        "outputId": "d915fd71-384d-461a-9c8d-0448b0879775"
      },
      "outputs": [],
      "source": [
        "fig = line([train_losses[::100], test_losses[::100]], x=np.arange(0, len(train_losses), 100), xaxis=\"Epoch\", yaxis=\"Loss\", log_y=False, \n",
        "     title=\"Training Curve for Modular Addition\", line_labels=['train', 'test'], return_fig=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig.show()\n",
        "fig.write_image(\"workspace/_scratch/training_curve.pdf\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see from the training curve that the model does indeed grok. The train is not able to get as low as the full model likely due to the lack of precision afforded by binarization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print out all parameters of model2\n",
        "for name, param in model2.named_parameters():\n",
        "    print(name, param.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(model2.transformer.layers[0].to_qkv[2].weight.size())\n",
        "print(model2.transformer.layers[0].to_out.weight.size())\n",
        "print(model2.transformer.ffn_layers[0].layer1.weight.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "W_V = model2.transformer.layers[0].to_qkv[2].weight\n",
        "W_K = model2.transformer.layers[0].to_qkv[1].weight\n",
        "W_Q = model2.transformer.layers[0].to_qkv[0].weight\n",
        "W_O = model2.transformer.layers[0].to_out.weight\n",
        "W_mlp_in = model2.transformer.ffn_layers[0].layer1.weight\n",
        "W_mlp_out = model2.transformer.ffn_layers[0].layer2.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.sign(W_mlp_in) @ torch.sign(W_O) @ torch.sign(W_V)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "import plotly.subplots as sp\n",
        "\n",
        "W_V = model2.transformer.layers[0].to_qkv[2].weight\n",
        "W_K = model2.transformer.layers[0].to_qkv[1].weight\n",
        "W_Q = model2.transformer.layers[0].to_qkv[0].weight\n",
        "W_O = model2.transformer.layers[0].to_out.weight\n",
        "W_mlp_in = model2.transformer.ffn_layers[0].layer1.weight\n",
        "W_mlp_out = model2.transformer.ffn_layers[0].layer2.weight\n",
        "\n",
        "def visualize_weights(W, title):\n",
        "    # Convert the tensor to numpy and then to int for visualization\n",
        "    W_np = (torch.sign(W)).detach().cpu().numpy().astype(int)\n",
        "\n",
        "    # Create the image\n",
        "    fig = px.imshow(W_np, color_continuous_scale=[\"white\", \"black\"], range_color=[-1,1])\n",
        "\n",
        "    # add a title\n",
        "    fig.update_layout(title=title)\n",
        "\n",
        "    # Show the image\n",
        "    return fig\n",
        "\n",
        "# Visualize each weight matrix\n",
        "visualize_weights(W_V, \"Binarized W_V visualized\").show()\n",
        "visualize_weights(W_K, \"Binarized W_K visualized\").show()\n",
        "visualize_weights(W_Q, \"Binarized W_Q visualized\").show()\n",
        "visualize_weights(W_O, \"Binarized W_O visualized\").show()\n",
        "visualize_weights(W_mlp_in, \"Binarized W_mlp_in visualized\").show()\n",
        "visualize_weights(W_mlp_out, \"Binarized W_mlp_out visualized\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that there does not exist any clear patterns to be discerned when we visualize one of the binarized weight matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xRPgGxZ2mEL"
      },
      "source": [
        "# Analysing the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpBxUIic2mEN"
      },
      "source": [
        "## Standard Things to Try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obgkfkAj2mEN",
        "outputId": "97ba669e-c323-43bc-f904-71399cf4cf32"
      },
      "outputs": [],
      "source": [
        "original_logits= model2(dataset)\n",
        "print(original_logits.numel())\n",
        "cache = model2.cache\n",
        "print(cache)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JHWCS7p2mEO"
      },
      "source": [
        "Get key weight matrices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "W_E = model2.emb.weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2sXW29z2mEO",
        "outputId": "13a414a6-4e0f-486e-b8dd-20922a918745"
      },
      "outputs": [],
      "source": [
        "original_loss = loss_fn(original_logits, labels).item()\n",
        "print(\"Original Loss:\", original_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwmbQzS62mEO"
      },
      "source": [
        "### Looking at Activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anSvj-UK2mEO"
      },
      "source": [
        "Helper variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neuron_acts = cache[\"post_activation_BitLinear\"][:, -1, :]\n",
        "neuron_pre_acts = cache[\"pre_activation_BitLinear\"][:, -1, :]\n",
        "print(neuron_acts.size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukgh0-U62mEO"
      },
      "source": [
        "Get all shapes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56qbhxlq2mEO",
        "outputId": "7c6a5328-4e59-474d-b2a0-e8cb32461515"
      },
      "outputs": [],
      "source": [
        "for param_name, param in cache.items():\n",
        "    print(param_name, param.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSuGH4mp2mEO",
        "outputId": "e2d74cd6-b325-4e03-daaa-b985511b44f6"
      },
      "outputs": [],
      "source": [
        "imshow(cache[\"attn_pattern_BitAttention\"].mean(dim=0)[:, -1, :], title=\"Average Attention Pattern per Head\", xaxis=\"Source\", yaxis=\"Head\", x=['a', 'b', '='])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mxU7WMX2mEO",
        "outputId": "64632f48-c429-42ef-b4cb-ac5dafd3ba5f"
      },
      "outputs": [],
      "source": [
        "dataset[:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cache[\"attn_pattern_BitAttention\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxpS6P-X2mEO",
        "outputId": "3248414e-91d6-4767-9bf3-a266d46144c5"
      },
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "import plotly.io as pio\n",
        "\n",
        "# Get the data\n",
        "data = cache[\"attn_pattern_BitAttention\"][:, 0, -1, 0].reshape(p, p)\n",
        "\n",
        "# Create the figure\n",
        "fig = go.Figure(data=go.Heatmap(z=data.cpu(), colorscale='Blues'))\n",
        "\n",
        "# Set the title, labels, and size\n",
        "fig.update_layout(title='Attention Score for Head 0', xaxis_title='b', yaxis_title='a', autosize=False, width=500, height=500)\n",
        "\n",
        "# Show the figure\n",
        "fig.show()\n",
        "\n",
        "# Save the figure\n",
        "pio.write_image(fig, 'workspace/_scratch/attention.pdf')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1dSftor2mEO",
        "outputId": "3777f927-5b39-491e-a98e-e38560476221"
      },
      "outputs": [],
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Create subplot structure\n",
        "fig = make_subplots(rows=1, cols=4, subplot_titles=[f'Head {i}' for i in range(4)])\n",
        "\n",
        "# Create individual plots\n",
        "for i in range(4):\n",
        "    img = einops.rearrange(cache[\"attn_pattern_BitAttention\"][:, i, -1, 0], \"(a b) -> a b\", a=p, b=p).cpu()\n",
        "    fig.add_trace(go.Heatmap(z=img, colorscale='Blues', showscale=False), row=1, col=i+1)\n",
        "\n",
        "# Update layout\n",
        "fig.update_layout(height=400, width=800, title_text=\"Attention for Each Head from a -> =\")\n",
        "fig.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pxuFVhn2mEP"
      },
      "source": [
        "Plotting neuron activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBhCsVhM2mEP",
        "outputId": "44b1ab6e-a9b7-409a-cedc-e5e266ac3a52"
      },
      "outputs": [],
      "source": [
        "imshow(\n",
        "    einops.rearrange(neuron_acts[:, :5], \"(a b) neuron -> neuron a b\", a=p, b=p),\n",
        "    title=\"First 5 neuron acts\", xaxis=\"b\", yaxis=\"a\", facet_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvbMfHKz2mEP"
      },
      "source": [
        "### Singular Value Decomposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JWb1keb2mEP",
        "outputId": "07c618ba-b820-4906-ab12-050ee9d4af0e"
      },
      "outputs": [],
      "source": [
        "W_E.shape\n",
        "# take off the last row\n",
        "W_E = W_E[:-1]\n",
        "W_E.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "en2HfhEE2mEP",
        "outputId": "d452d212-4c98-40d0-debc-5e15132f4aba"
      },
      "outputs": [],
      "source": [
        "U, S, Vh = torch.svd(W_E)\n",
        "line(S, title=\"Singular Values\")\n",
        "imshow(U, title=\"Principal Components on the Input\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One difference this has compared to the full precision grokked model is that there seems to be more components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7gs3i4U2mEP",
        "outputId": "cdb69c3e-2a62-4e1d-d96a-5e9bd8b70fb1"
      },
      "outputs": [],
      "source": [
        "# Control - random Gaussian matrix\n",
        "U, S, Vh = torch.svd(torch.randn_like(W_E))\n",
        "line(S, title=\"Singular Values Random\")\n",
        "imshow(U, title=\"Principal Components Random\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVW_V0ub2mEP"
      },
      "source": [
        "## Explaining Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-m5Y-r82mEP"
      },
      "source": [
        "### Analyse the Embedding - It's a Lookup Table!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBSK8lk52mEP",
        "outputId": "151ad1c9-bff2-449d-bf97-233fe6ca8eb0"
      },
      "outputs": [],
      "source": [
        "U, S, Vh = torch.svd(W_E)\n",
        "line(U[:, :15].T, title=\"Principal Components of the embedding\", xaxis=\"Input Vocabulary\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJvvhkeS2mEP",
        "outputId": "dd7424f3-9833-4dfc-fbf9-1f130984569f"
      },
      "outputs": [],
      "source": [
        "fourier_basis = []\n",
        "fourier_basis_names = []\n",
        "fourier_basis.append(torch.ones(p))\n",
        "fourier_basis_names.append(\"Constant\")\n",
        "for freq in range(1, p//2+2):\n",
        "    fourier_basis.append(torch.sin(torch.arange(p)*2 * torch.pi * freq / p))\n",
        "    fourier_basis_names.append(f\"Sin {freq}\")\n",
        "    fourier_basis.append(torch.cos(torch.arange(p)*2 * torch.pi * freq / p))\n",
        "    fourier_basis_names.append(f\"Cos {freq}\")\n",
        "fourier_basis = torch.stack(fourier_basis, dim=0).cuda()\n",
        "fourier_basis = fourier_basis/fourier_basis.norm(dim=-1, keepdim=True)\n",
        "imshow(fourier_basis, xaxis=\"Input\", yaxis=\"Component\", y=fourier_basis_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oy6DWo0_2mEP",
        "outputId": "85d1f8c4-ba97-4f71-eb97-ea5eb71f911b"
      },
      "outputs": [],
      "source": [
        "line(fourier_basis[:8], xaxis=\"Input\", line_labels=fourier_basis_names[:8], title=\"First 8 Fourier Components\")\n",
        "line(fourier_basis[25:29], xaxis=\"Input\", line_labels=fourier_basis_names[25:29], title=\"Middle Fourier Components\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbU6PR0Y2mEP",
        "outputId": "128cbec4-abc2-479a-d1b6-6f6a9094c67d"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis @ fourier_basis.T, title=\"All Fourier Vectors are Orthogonal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a3g2YGP2mEQ"
      },
      "source": [
        "### Analyse the Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcVaP3qo2mEQ",
        "outputId": "8cebd5ef-2630-4d2d-f403-4b9ab02486be"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis @ W_E, yaxis=\"Fourier Component\", xaxis=\"Residual Stream\", y=fourier_basis_names, title=\"Embedding in Fourier Basis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once again this is alot less \"clean\" compared to the full precision model but still seems to be fundamentally the same thing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute the norm\n",
        "norm_values = (fourier_basis @ W_E).norm(dim=-1)\n",
        "\n",
        "# Convert the tensor to a numpy array for plotting\n",
        "norm_values_np = norm_values.detach().cpu().numpy()\n",
        "\n",
        "# Create the plot\n",
        "fig = go.Figure(data=go.Bar(y=norm_values_np))\n",
        "\n",
        "# Set the title and labels\n",
        "fig.update_layout(title='Norm of Tensor', xaxis_title='Index', yaxis_title='Norm')\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Compute the norm\n",
        "norm_values = (fourier_basis @ W_E).norm(dim=-1)\n",
        "\n",
        "# Convert the tensor to a numpy array for plotting\n",
        "norm_values_np = norm_values.detach().cpu().numpy()\n",
        "\n",
        "# Create indices for sin and cos\n",
        "indices = np.arange(len(norm_values_np))\n",
        "sin_indices = indices[indices % 2 == 0]\n",
        "cos_indices = indices[indices % 2 == 1]\n",
        "\n",
        "# Create the plot with alternating colors\n",
        "fig = go.Figure(data=[\n",
        "    go.Bar(x=sin_indices, y=norm_values_np[sin_indices], name='sin', marker_color='blue'),\n",
        "    go.Bar(x=cos_indices, y=norm_values_np[cos_indices], name='cos', marker_color='red')\n",
        "])\n",
        "\n",
        "# Set the title and labels\n",
        "fig.update_layout(\n",
        "    title='Fourier Components of Embedding Matrix',\n",
        "    xaxis_title='Frequency',\n",
        "    yaxis_title='Norm',\n",
        "    barmode='group',\n",
        "    xaxis=dict(\n",
        "        tickmode='array',\n",
        "        tickvals=list(range(0, len(norm_values_np), 20)),  # Show only every 10th label\n",
        "        ticktext=list(range(0, len(norm_values_np) // 2, 10))  # Show only every 10th label\n",
        "    )\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n",
        "pio.write_image(fig, 'workspace/_scratch/fourier_emb.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-194xOZ2mEQ",
        "outputId": "0c0cd107-a7ee-4bf0-d7f6-84fcf903368e"
      },
      "outputs": [],
      "source": [
        "line((fourier_basis @ W_E).norm(dim=-1), xaxis=\"Fourier Component\", yaxis=\"Norm of Fourier Component\", x=fourier_basis_names, title=\"Norms of Embedding in Fourier Basis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-eKHNUE2mEQ",
        "outputId": "b11d7aba-fc9a-49b7-a148-36f9468c6099"
      },
      "outputs": [],
      "source": [
        "# key_freqs = [17, 25, 32, 47]\n",
        "fourier_embed = fourier_basis @ W_E\n",
        "# key freq indices are those for which the fourier_embed are higher than 0.1\n",
        "key_freq_indices = (fourier_embed.norm(dim=-1) > 0.1).nonzero().squeeze().tolist()\n",
        "print(key_freq_indices)\n",
        "key_fourier_embed = fourier_embed[key_freq_indices]\n",
        "print(\"key_fourier_embed\", key_fourier_embed.shape)\n",
        "imshow(key_fourier_embed @ key_fourier_embed.T, title=\"Dot Product of embedding of key Fourier Terms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One difference this graph shows compared to the full precision model is that the terms are not as orthogonal. I hypothesize that this is due to the lack of precision of binarization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl6EqP3U2mEQ"
      },
      "source": [
        "### Key Frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "od3EQTQL2mEQ",
        "outputId": "34916208-dd4f-417e-c56a-f5cf4c79cb56"
      },
      "outputs": [],
      "source": [
        "import neel_plotly as npx\n",
        "key_cos = [num for num in key_freq_indices if num % 2 == 0]\n",
        "npx.line(fourier_basis[key_cos], title=\"Cos of key freqs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aViDwpe_2mEQ",
        "outputId": "60784b17-90d2-45d3-c573-5ae2dc9e0917"
      },
      "outputs": [],
      "source": [
        "npx.line(fourier_basis[key_cos].mean(0), title=\"Constructive Interference\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n98Zr5uU2mEQ"
      },
      "source": [
        "## Analyse Neurons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwwUrv1s2mEQ",
        "outputId": "b5fe1aec-5f37-4b73-e12a-86599f951eaa"
      },
      "outputs": [],
      "source": [
        "imshow(\n",
        "    einops.rearrange(neuron_acts[:, :5], \"(a b) neuron -> neuron a b\", a=p, b=p),\n",
        "    title=\"First 5 neuron acts\", xaxis=\"b\", yaxis=\"a\", facet_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbmEf5Vs2mEQ",
        "outputId": "925c0567-759b-4ba0-8a5b-da11392326a4"
      },
      "outputs": [],
      "source": [
        "# Get the data\n",
        "data = einops.rearrange(neuron_acts[:, 0], \"(a b) -> a b\", a=p, b=p)\n",
        "\n",
        "# Create the figure\n",
        "fig = go.Figure(data=go.Heatmap(z=data.cpu(), colorscale='Blues'))\n",
        "\n",
        "# Set the title, labels, and size\n",
        "fig.update_layout(title='First neuron act', xaxis_title='b', yaxis_title='a', autosize=False, width=500, height=500)\n",
        "\n",
        "# Show the figure\n",
        "fig.show()\n",
        "\n",
        "pio.write_image(fig, 'workspace/_scratch/activation.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beudDuCV2mEQ",
        "outputId": "d5706cfd-c76e-4c36-fec7-33c250d79b36"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis @ neuron_acts[:, 0].reshape(p, p) @ fourier_basis.T, title=\"2D Fourier Transformer of neuron 0\", xaxis=\"b\", yaxis=\"a\", x=fourier_basis_names, y=fourier_basis_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8HQJ63l2mER",
        "outputId": "fdf279ba-496d-494b-ff8c-632a992a31d7"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis @ neuron_acts[:, 4].reshape(p, p) @ fourier_basis.T, title=\"2D Fourier Transformer of neuron 4\", xaxis=\"b\", yaxis=\"a\", x=fourier_basis_names, y=fourier_basis_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoLpq8tg2mER"
      },
      "source": [
        "### Neuron Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_wBdZ9-2mER",
        "outputId": "069f7406-3236-4599-af28-b14cbe56c725"
      },
      "outputs": [],
      "source": [
        "fourier_neuron_acts = fourier_basis @ einops.rearrange(neuron_acts, \"(a b) neuron -> neuron a b\", a=p, b=p) @ fourier_basis.T\n",
        "# Center these by removing the mean - doesn't matter!\n",
        "fourier_neuron_acts[:, 0, 0] = 0.\n",
        "print(\"fourier_neuron_acts\", fourier_neuron_acts.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RiVxk4W2mER",
        "outputId": "bef04322-7a69-459d-c916-9a0727b13b72"
      },
      "outputs": [],
      "source": [
        "neuron_freq_norm = torch.zeros(p//2, cfg.d_mlp).cuda()\n",
        "for freq in range(0, p//2):\n",
        "    for x in [0, 2*(freq+1) - 1, 2*(freq+1)]:\n",
        "        for y in [0, 2*(freq+1) - 1, 2*(freq+1)]:\n",
        "            neuron_freq_norm[freq] += fourier_neuron_acts[:, x, y]**2\n",
        "neuron_freq_norm = neuron_freq_norm / fourier_neuron_acts.pow(2).sum(dim=[-1, -2])[None, :]\n",
        "imshow(neuron_freq_norm, xaxis=\"Neuron\", yaxis=\"Freq\", y=torch.arange(1, p//2+1), title=\"Neuron Frac Explained by Freq\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Calculate the maximum values along the 0th dimension\n",
        "max_values = neuron_freq_norm.max(0).values\n",
        "\n",
        "# Create an array of indices\n",
        "indices = list(range(len(max_values)))\n",
        "\n",
        "# Create the bar graph\n",
        "fig = go.Figure(data=[go.Bar(x=indices, y=max_values.cpu().numpy())])\n",
        "\n",
        "# Add labels and title\n",
        "fig.update_layout(title='Max Values of neuron_freq_norm', xaxis_title='Index', yaxis_title='Max Value')\n",
        "\n",
        "# Display the plot\n",
        "fig.show()\n",
        "\n",
        "# Create the histogram\n",
        "fig = go.Figure(data=go.Histogram(x=max_values.cpu(), nbinsx=10, histnorm=''))\n",
        "\n",
        "# Set the bin size\n",
        "fig.update_traces(xbins=dict(start=0, end=1, size=0.05))\n",
        "\n",
        "# Set the title and labels\n",
        "fig.update_layout(title='FVE by degree 2 polynomials (Binary)', xaxis_title='Fraction of Variance Explained', yaxis_title='Number of Neurons')\n",
        "\n",
        "# Show the figure\n",
        "fig.show()\n",
        "pio.write_image(fig, 'workspace/_scratch/fve.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLTnNgUC2mER",
        "outputId": "bb90671f-4c27-408e-a1a6-1f236545e417"
      },
      "outputs": [],
      "source": [
        "line(neuron_freq_norm.max(dim=0).values.sort().values, xaxis=\"Neuron\", title=\"Max Neuron Frac Explained over Freqs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "neuron_freq_norm.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Get the data\n",
        "neuron_acts_square = einops.rearrange(neuron_acts, \"(a b) neur -> a b neur\", a=p, b=p).clone()\n",
        "neuron_acts_square -= einops.reduce(neuron_acts_square, \"a b neur -> 1 1 neur\", \"mean\")\n",
        "neuron_acts_square_fourier = einsum(\"a b neur, fa a, fb b -> fa fb neur\", neuron_acts_square, fourier_basis, fourier_basis)\n",
        "\n",
        "# Create the data for the heatmap\n",
        "data = neuron_acts_square_fourier.norm(dim=-1)\n",
        "\n",
        "# Create the figure\n",
        "fig = go.Figure(data=go.Heatmap(z=data.cpu(), colorscale='Blues', x=fourier_basis_names, y=fourier_basis_names))\n",
        "\n",
        "# Set the title and labels\n",
        "fig.update_layout(title={\n",
        "        'text': \"Norms of neuron activations<br>by Fourier Component\",\n",
        "        'y':0.9,\n",
        "        'x':0.5,\n",
        "        'xanchor': 'center',\n",
        "        'yanchor': 'top',\n",
        "        'font': dict(\n",
        "            size=15\n",
        "        )\n",
        "    }, xaxis_title='Fourier Component b', yaxis_title='Fourier Component a',autosize=False, width=500, height=500)\n",
        "\n",
        "# Show the figure\n",
        "fig.show()\n",
        "\n",
        "pio.write_image(fig, 'workspace/_scratch/neuron_acts_fourier.pdf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary of Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Overall, all of the graphs I've generated seem to align with the graphs of the full precision models from the original reverse engineering modular addition code from https://youtu.be/o0FppeD_xXQ?si=ObA2aISAUQI_H2GC\n",
        "\n",
        "While this investigation is not exactly thorough, it is pretty clear at least that there is no evidence to support my initial hypothesis that binarized transformers can learn a more discretized and more interpretable representation. Instead, all of evidence seems to suggest instead that the binarized setup is instead learning an algorithm which is mostly the same as the one being learned by the full precision model.\n",
        "\n",
        "From this preliminary investigation, I further hypothesize that this result is due to the fact that the start and end with the embed and unembed layers are not binarized so they are still free to learn the fourier transform which are the most important parts to this. Furthermore, I think that in general, binarized networks will end up learning approximations of full precision networks. This is because the optimization techniques used such as the straight-through estimator of the gradient used by BitNet aim to treat the binarization mechanism as a continuous function to be optimized over."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "8859a5491331dba93123a91c2831400aced845b502848170e05fcb48b2c144be"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
